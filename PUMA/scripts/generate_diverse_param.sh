accelerate launch test_llama.py \
    --model_path output/input/Llama-2-7b-chat-hf/ \
    --base_model meta-llama/Llama-2-7b-chat-hf \
    --data_path data/param.json \
    --bf16 \
    --split train \
    --test_on param \
    --batch_size 4 \
    --max_new_tokens 256 \
    --tool_file output/res/ \
    --res_file output/res/ \
    --memory_length 256 \
    --num_beams 10 \
    --temperature 1.5 \
    --do_sample \